TEXT_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
CLIP_MODEL = "openai/clip-vit-base-patch32"

CHUNK_SIZE = 500
OVERLAP = 100

DATA_DIR = "data"
CHUNK_DIR = "chunks"
EMBED_DIR = "embeddings"
FAISS_DIR = "faiss_indexes"
